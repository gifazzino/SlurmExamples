/local/anaconda3/envs/acorn_env/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /local/anaconda3/envs/acorn_env/bin/acorn train metr ...
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
You are using a CUDA device ('NVIDIA RTX A6000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 2 processes
----------------------------------------------------------------------------------------------------
Loaded 0 training events, 0 validation events and 0 testing events

/misc/home/atlas/gfazzino/acorn/acorn/utils/loading_utils.py:62: UserWarning: Found an empty dataset. Please check if this is not intended.
  warnings.warn(
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]

  | Name    | Type       | Params | Mode
-----------------------------------------------
0 | network | Sequential | 3.2 M  | train
-----------------------------------------------
3.2 M     Trainable params
0         Non-trainable params
3.2 M     Total params
12.661    Total estimated model params size (MB)
14        Modules in train mode
0         Modules in eval mode
                                                  
/local/anaconda3/envs/acorn_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/local/anaconda3/envs/acorn_env/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:105: Total length of `DataLoader` across ranks is zero. Please make sure this was your intention.
/local/anaconda3/envs/acorn_env/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:105: Total length of `CombinedLoader` across ranks is zero. Please make sure this was your intention.
`Trainer.fit` stopped: No training batches.
